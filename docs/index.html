<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">

  <!-- Meta tags -->
  <meta name="description" content="NonOpt: Nonconvex, Nonsmooth Optimizer">
  <meta property="og:title" content="NonOpt: Nonconvex, Nonsmooth Optimizer"/>
  <meta property="og:description" content="NonOpt: Nonconvex, Nonsmooth Optimizer"/>
  <meta property="og:url" content="https://frankecurtis.github.io/NonOpt/"/>

  <!-- Keywords -->
  <meta name="keywords" content="optimization nonconvex convex nonsmooth smooth continuous">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Title -->
  <title>NonOpt</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Style sheets -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Scripts -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>  
</head>
<body>

<!-- Title -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">NonOpt</h1>
          <h2 class="title is-4 publication-title">Nonconvex, Nonsmooth Optimizer</h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- end Title -->

<!-- About -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-4">About</h2>
        <div class="content has-text-justified">
          <p>
            NonOpt is an open-source C++ software package for solving unconstrained optimization problems of the form
            \[
              \min_{x \in \mathbb{R}^n} f(x)
            \]
            where \(f : \mathbb{R}^n \to \mathbb{R}\) is locally Lipschitz.  The objective function \(f\) may be nonconvex and/or nonsmooth.
          </p>
          <p>
            NonOpt can be obtained on GitHub <a href="https://github.com/frankecurtis/NonOpt"><strong>here (link)</strong></a>.  A direct link to its user manual is <a href="https://github.com/frankecurtis/NonOpt/blob/main/NonOpt-Manual/NonOpt.pdf"><strong>here (link)</strong></a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- end About -->

<!-- Developers -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-4">Developers (Current)</h2>
        <div class="content has-text-centered">
          <div class="columns">
            <div class="column">
              <img src="static/images/fec.jpg" alt="Frank E. Curtis" class="blend-img-background center-image" style="max-width: 60%; height: auto;" />
              <p>
                <em><strong>Frank E. Curtis</strong></em>
                <br>
                main developer
                <br>
                <a href="https://coral.ise.lehigh.edu/frankecurtis/" target=_blank><strong>website (link)</strong></a>
              </p>
            </div>
            <div class="column">
              <img src="static/images/lara.png" alt="Lara Zebiane" class="blend-img-background center-image" style="max-width: 60%; height: auto;" />
              <p>
                <em><strong>Lara Zebiane</strong></em>
                <br>
                interior-point subproblem solver
                <br>
                <a href="https://coral.ise.lehigh.edu/laz223/" target=_blank><strong>website (link)</strong></a>
              </p>
            </div>
          </div>
        </div>
        <h2 class="title is-4">Developers (Former)</h2>
        <div class="content has-text-centered">
          <div class="columns">
            <div class="column">
              <img src="static/images/baoyu.jpg" alt="Baoyu Zhou" class="blend-img-background center-image" style="max-width: 60%; height: auto;" />
              <p>
                <em><strong>Baoyu Zhou</strong></em>
                <br>
                active-set subproblem solver
                <br>
                <a href="https://baoyuzhou18.github.io/" target=_blank><strong>website (link)</strong></a>
              </p>
            </div>
            <div class="column">
              <img src="static/images/minhan.jpg" alt="Minhan Li" class="blend-img-background center-image" style="max-width: 60%; height: auto;" />
              <p>
                <em><strong>Minhan Li</strong></em>
                <br>
                inexactness and aggregation conditions
                <br>
                <a href="https://www.linkedin.com/in/minhan-li-830008104/" target=_blank><strong>website (link)</strong></a>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- end Developers -->

<!-- Further details -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-4">Further details</h2>
        <div class="content has-text-justified">
          <p>
            NonOpt contains a suite of algorithms for solving locally Lipschitz (potentially nonconvex and/or nonsmooth) minimization problems.  It is not guaranteed to find a global minimizer of the objective function.  Rather, it employs local-search techniques based on (generalized) derivative computations in order to improve as best as it can upon an initial solution estimate.
          </p>
          <p>
            To use NonOpt, a user only needs to provide a method for evaluating an objective function and a (generalized) gradient for it at any given solution estimate.  (Various examples are provided that a user can follow to implement their own problem.)  NonOpt's default parameters have been chosen as those that often allow the software to find a good solution estimate relatively quickly.  A user can adjust these parameters through options in the software in order to push the solver to try to find solutions of higher accuracy.  For further information about how to adjust input parameters, please see the User's Manual <a href="https://github.com/frankecurtis/NonOpt/blob/main/NonOpt-Manual/NonOpt.pdf"><strong>here (link)</strong></a>.
          </p>
          <p>
            The algorithms implemented in NonOpt are based on three main methodologies, namely, the quasi-Newton, proximal-bundle, and gradient-sampling methodologies.  For further information about each of these methodologies, please see the (forthcoming) book ``Practical Nonconvex Nonsmooth Optimization'' <a href="https://sufficientdescent.github.io/practicalnonconvexnonsmooth"><strong>here (link)</strong></a>.  Here we provide only brief descriptions.
          </p>
          <p>
            Quasi-Newton techniques were first designed for the setting of minimizing smooth functions.  They involve using first-order derivatives in order to approximate second-order derivatives through iterative updates.  In particular, given first-order derivatives at solution estimates indexed by \(k\) and \(k+1\), call these estimates \(x_k\) and \(x_{k+1}\), the foundational idea of any quasi-Newton method is to approximate the second-order derivative (i.e., Hessian matrix) of the objective function at \(x_{k+1}\), call it \(H_{k+1}\), in such a way that the resulting second-order approximation of the objective at \(x_{k+1}\) has a derivative that matches the derivative of the original objective at \(x_k\).  This is known as the secant equation; see the figure below, where by satisfying the secant equation the resulting second-order approximation of the objective at \(x_{k+1}\) (purple curve) has a derivative that matches the derivative of the objective function (blue curve) at \(x_k\).  Despite the fact that this foundational idea was first developed for the setting of smooth optimization, quasi-Newton techniques turn out to be extremely powerful when solving nonsmooth minimization problems as well.  All algorithms in NonOpt use quasi-Newton techniques.
          </p>
        </div>
        <div class="content has-text-centered">
          <p>
            <img src="static/images/quasi_newton.png" alt="Quasi-Newton Image" class="center" width="300"/>
          </p>
        </div>
        <div class="content has-text-justified">
          <p>
            The default algorithm that NonOpt employs is based on the proximal-bundle methodology (equipped with a quasi-Newton technique) for computing search directions.  Proximal-bundle methods build on the classic cutting-plane methodology for approximating a function through point-wise maxima over sets of affine approximations.  For convex functions, these cutting planes underestimate the objective function at every point in the domain.  Combined with the proximal-point methodology, the resulting piecewise-quadratic approximations no longer underestimate the objective function, but they approximate it sufficiently well for the purpose of computing search directions.  See the figure below, where on the left the quadratic approximation of the objective, namely, \(q_{\cal{B}_{k,j}}\), is constructed using only one cutting plane, whereas on the right the piecewise quadratic approximation is constructed with two cutting planes.  Convergence guarantees for the algorithm are based on tying the resulting approximations to a function known as the Moreau envelope, which is shown as \(\tilde{f}\) in the illustrations below.
          </p>
        </div>
        <div class="content has-text-centered">
          <p>
            <img src="static/images/proximal_bundle.png" alt="Proximal Bundle Image" class="center" width="600"/>
          </p>
        </div>
        <div class="content has-text-justified">
          <p>
            The other main algorithm available in NonOpt is based on the gradient-sampling methodology.  The fundamental idea of the gradient-sampling methodology is to approximate, at each solution estimate, a steepest-descent direction through the random sampling of points and computation of gradients of the objective function at those points.  The computed search direction is then the minimum-norm element of the convex hull of these available gradients from nearby points.  If the points that are sampled surround a minimizer, such as on the left in the figure below, then the search direction may be zero, in which case the algorithm adaptively decreases the radius over which the points are sampled.  This can lead to a situation such as that illustrated on the right below, where a nonzero search direction can equivalently be described as being computed by minimizing a piecewise-quadratic approximation of the objective function at the solution estimate \(x_{k+1}\).
          </p>
        </div>
        <div class="content has-text-centered">
          <p>
            <img src="static/images/gradient_sampling.png" alt="Gradient Sampling Image" class="center" width="600"/>
          </p>
        </div>
        <div class="content has-text-justified">
          <p>
            These are only very brief descriptions of the algorithmic methodologies underlying NonOpt.  We encourage any user that is interested to check out the (forthcoming) book ``Practical Nonconvex Nonsmooth Optimization'' <a href="https://sufficientdescent.github.io/practicalnonconvexnonsmooth"><strong>here (link)</strong></a> for much more in-depth discussions about these methodologies and their use for locally Lipschitz minimization.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- end Further details -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-4">Citations</h2>
        <p>The main citation for NonOpt is the following.  If you use NonOpt in your research, then please cite it.  We appreciate it!</p>
      </div>
    </div>
  </div>
  <br>
  <div class="container is-max-desktop content">
    <pre><code>
      @article{CurtZebi2025,
      title={NonOpt: Nonconvex, Nonsmooth Optimizer},
      author={Frank E. Curtis and Lara Zebiane},
      journal={arXiv preprint arXiv:2503.22826},
      year={2025}
      }
    </code></pre>
  </div>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <p>NonOpt is also based on the following papers.  We hope you find them useful, and, if so, cite them as well.</p>
      </div>
    </div>
  </div>
  <br>
  <div class="container is-max-desktop content">
    <pre><code>
      @article{CurtQue2013,
        author = {Frank E. Curtis and Xiaocun Que},
        title = {{An Adaptive Gradient Sampling Algorithm for Nonsmooth Optimization}},
        journal = {{Optimization Methods and Software}},
        volume = {28},
        number = {6},
        pages = {1302--1324},
        year = {2013}
      }
      @article{CurtQue2015,
        author = {Frank E. Curtis and Xiaocun Que},
        title = {{A Quasi-Newton Algorithm for Nonconvex, Nonsmooth Optimization with Global Convergence Guarantees}},
        journal = {{Mathematical Programming Computation}},
        volume = {7},
        number = {4},
        pages = {399--428},
        year = {2015}
      }
      @article{CurtRobiZhou2020,
        author = {Frank E. Curtis and Daniel P. Robinson and Baoyu Zhou},
        title = {{A Self-Correcting Variable-Metric Algorithm Framework for Nonsmooth Optimization}},
        journal = {{IMA Journal of Numerical Analysis}},
        volume = {40},
        number = {2},
        pages = {1154--1187},
        year = {2020}
      }
      @article{CurtLi22,
        author = {Frank E. Curtis and Minhan Li},
        title = {{Gradient Sampling Methods with Inexact Subproblem Solutions and Gradient Aggregation}},
        journal = {{INFORMS Journal on Optimization}},
        volume = {4},
        number = {4},
        pages = {347--445},
        year = {2022}
      }
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->

<!-- footer -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br>
            Licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!-- end footer -->

</body>
</html>